{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8HQYsAtC0Fv",
    "tags": []
   },
   "source": [
    "# Classifying Images using Dropout and Batchnorm Layer\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, you learn how to build a neural network to classify the tf-flowers dataset using dropout and batchnorm layer.\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "* Define Helper Functions.\n",
    "* Apply dropout and batchnorm layer.\n",
    "\n",
    "\n",
    "Each learning objective will correspond to a __#TODO__ in the student lab notebook -- try to complete this notebook first and then review the [solution notebook](../solutions/classifying_images_using_dropout_and_batchnorm_layer.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugGJcxKAwhc2",
    "outputId": "f25e3267-1495-48f8-d6e1-4da24dd41755",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helper Functions\n",
    "#### Reading and Preprocessing image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LKXV5oRmkSTK"
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def training_plot(metrics, history):\n",
    "  f, ax = plt.subplots(1, len(metrics), figsize=(5*len(metrics), 5))\n",
    "  for idx, metric in enumerate(metrics):\n",
    "    ax[idx].plot(history.history[metric], ls='dashed')\n",
    "    ax[idx].set_xlabel(\"Epochs\")\n",
    "    ax[idx].set_ylabel(metric)\n",
    "    ax[idx].plot(history.history['val_' + metric]);\n",
    "    ax[idx].legend([metric, 'val_' + metric])\n",
    "\n",
    "# Call model.predict() on a few images in the evaluation dataset\n",
    "def plot_predictions(filename):\n",
    "  f, ax = plt.subplots(3, 5, figsize=(25,15))\n",
    "  dataset = (tf.data.TextLineDataset(filename).\n",
    "      map(decode_csv))\n",
    "  for idx, (img, label) in enumerate(dataset.take(15)):\n",
    "    ax[idx//5, idx%5].imshow((img.numpy()));\n",
    "    batch_image = tf.reshape(img, [1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS])\n",
    "    batch_pred = model.predict(batch_image)\n",
    "    pred = batch_pred[0]\n",
    "    label = CLASS_NAMES[label.numpy()]\n",
    "    pred_label_index = tf.math.argmax(pred).numpy()\n",
    "    pred_label = CLASS_NAMES[pred_label_index]\n",
    "    prob = pred[pred_label_index]\n",
    "    ax[idx//5, idx%5].set_title('{}: {} ({:.4f})'.format(label, pred_label, prob))\n",
    "\n",
    "def show_trained_weights(model):\n",
    "  # CLASS_NAMES is ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
    "  LAYER = 1 # Layer 0 flattens the image, layer=1 is the first dense layer\n",
    "  WEIGHT_TYPE = 0 # 0 for weight, 1 for bias\n",
    "\n",
    "  f, ax = plt.subplots(1, 5, figsize=(15,15))\n",
    "  for flower in range(len(CLASS_NAMES)):\n",
    "    weights = model.layers[LAYER].get_weights()[WEIGHT_TYPE][:, flower]\n",
    "    min_wt = tf.math.reduce_min(weights).numpy()\n",
    "    max_wt = tf.math.reduce_max(weights).numpy()\n",
    "    flower_name = CLASS_NAMES[flower]\n",
    "    print(\"Scaling weights for {} in {} to {}\".format(\n",
    "        flower_name, min_wt, max_wt))\n",
    "    weights = (weights - min_wt)/(max_wt - min_wt)\n",
    "    ax[flower].imshow(weights.reshape(IMG_HEIGHT, IMG_WIDTH, 3));\n",
    "    ax[flower].set_title(flower_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ATwrq3yQXCZ3",
    "outputId": "211a7575-abf1-44a4-c15c-2d264d885f99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the available classes: ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 14:40:36.162129: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-10-04 14:40:36.162214: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-10-04 14:40:36.162243: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-20231004-195108): /proc/driver/nvidia/version does not exist\n",
      "2023-10-04 14:40:36.166099: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "def read_and_decode(filename, reshape_dims):\n",
    "  # Read the file\n",
    "  img = tf.io.read_file(filename)\n",
    "  # Convert the compressed string to a 3D uint8 tensor.\n",
    "  img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "  # Resize the image to the desired size.\n",
    "  # TODO 1 -- Your code here\n",
    "  return tf.image.resize(img, reshape_dims)  \n",
    "\n",
    "CLASS_NAMES = [item.numpy().decode(\"utf-8\") for item in \n",
    "               tf.strings.regex_replace(\n",
    "                 tf.io.gfile.glob(\"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/*\"),\n",
    "                 \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/\", \"\")]\n",
    "CLASS_NAMES = [item for item in CLASS_NAMES if item.find(\".\") == -1]\n",
    "print(\"These are the available classes:\", CLASS_NAMES)\n",
    "\n",
    "# the label is the index into CLASS_NAMES array\n",
    "def decode_csv(csv_row):\n",
    "  record_defaults = [\"path\", \"flower\"]\n",
    "  filename, label_string = tf.io.decode_csv(csv_row, record_defaults)\n",
    "  img = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n",
    "  label = tf.argmax(tf.math.equal(CLASS_NAMES, label_string))\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Duu8mX3iXANE",
    "tags": []
   },
   "source": [
    "## Apply dropout and batchnorm layer\n",
    "A deep neural network (DNN) is a neural network with more than one hidden layer. Each time you add a layer, the number of trainable parameters increases. Therefore,you need a larger dataset. You still have only 3700 flower images which might cause overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropouts are the regularization technique that is used to prevent overfitting in the model. Batch normalization is a layer that allows every layer of the network to do learning more independently. The layer is added to the sequential model to standardize the input or the outputs. Add a dropout and batchnorm layer after each of the hidden layers.\n",
    "\n",
    "#### Dropout\n",
    "Dropout is one of the oldest regularization techniques in deep learning. At each training iteration, it drops random neurons from the network with a probability p (typically 25% to 50%). In practice, neuron outputs are set to 0. The net result is that these neurons will not participate in the loss computation this time around and they will not get weight updates. Different neurons will be dropped at each training iteration.\n",
    "#### Batch normalization\n",
    "Our input pixel values are in the range [0,1] and this is compatible with the dynamic range of the typical activation functions and optimizers. However, once we add a hidden layer, the resulting output values will no longer lie in the dynamic range of the activation function for subsequent layers. When this happens, the neuron output is zero, and because there is no difference by moving a small amount in either direction, the gradient is zero. There is no way for the network to escape from the dead zone. To fix this, batch norm normalizes neuron outputs across a training batch of data, i.e. it subtracts the average and divides by the standard deviation. This way, the network decides, through machine learning, how much centering and re-scaling to apply at each neuron. In Keras, you can selectively use one or the other:\n",
    "\n",
    "`tf.keras.layers.BatchNormalization(scale=False, center=True)`\n",
    "\n",
    "When using batch normalization, remember that:\n",
    "1. Batch normalization goes between the output of a layer and its activation function. So, rather than set activation='relu' in the Dense layer’s constructor, we’d omit the activation function, and then add a separate Activation layer.\n",
    "2. If you use center=True in batch norm, you do not need biases in your layer. The batch norm offset plays the role of a bias.\n",
    "3. If you use an activation function that is scale-invariant (i.e. does not change shape if you zoom in on it) then you can set scale=False. ReLu is scale-invariant. Sigmoid is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7OxxAryMXH1k"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(batch_size = 32,\n",
    "                       lrate = 0.0001,\n",
    "                       l1 = 0,\n",
    "                       l2 = 0.001,\n",
    "                       dropout_prob = 0.4,\n",
    "                       num_hidden = [64, 16]):\n",
    "  regularizer = tf.keras.regularizers.l1_l2(l1, l2)\n",
    "\n",
    "  train_dataset = (tf.data.TextLineDataset(\n",
    "      \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/train_set.csv\").\n",
    "      map(decode_csv)).batch(batch_size)\n",
    "\n",
    "  eval_dataset = (tf.data.TextLineDataset(\n",
    "      \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/eval_set.csv\").\n",
    "      map(decode_csv)).batch(32) # this doesn't matter\n",
    "\n",
    "  # NN with multiple hidden layers\n",
    "  layers = [tf.keras.layers.Flatten(\n",
    "      input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n",
    "      name='input_pixels')]\n",
    "  for hno, nodes in enumerate(num_hidden):\n",
    "    layers.extend([\n",
    "      tf.keras.layers.Dense(nodes,\n",
    "                            kernel_regularizer=regularizer, \n",
    "                            name='hidden_dense_{}'.format(hno)),\n",
    "      tf.keras.layers.BatchNormalization(scale=False, # ReLU\n",
    "                                         center=False, # have bias in Dense\n",
    "                                         name='batchnorm_dense_{}'.format(hno)),\n",
    "      #move activation to come after batchnorm\n",
    "      tf.keras.layers.Activation('relu', name='relu_dense_{}'.format(hno)),\n",
    "\n",
    "  # TODO 2 -- Your code here\n",
    "      tf.keras.layers.Dropout(rate=dropout_prob,\n",
    "                             name='dropout_dense_{}'.format(hno)),                         \n",
    "    ])\n",
    "  layers.append(\n",
    "      tf.keras.layers.Dense(len(CLASS_NAMES), \n",
    "                            kernel_regularizer=regularizer,\n",
    "                            activation='softmax',\n",
    "                            name='flower_prob')\n",
    "  )\n",
    "\n",
    "  model = tf.keras.Sequential(layers, name='flower_classification')\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lrate),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                    from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "  print(model.summary())\n",
    "  history = model.fit(train_dataset, validation_data=eval_dataset, epochs=10)\n",
    "  training_plot(['loss', 'accuracy'], history)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nNDruEBPXPLD",
    "outputId": "94ad4651-894e-4646-a901-92ae7419fea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"flower_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_pixels (Flatten)       (None, 150528)            0         \n",
      "_________________________________________________________________\n",
      "hidden_dense_0 (Dense)       (None, 64)                9633856   \n",
      "_________________________________________________________________\n",
      "batchnorm_dense_0 (BatchNorm (None, 64)                128       \n",
      "_________________________________________________________________\n",
      "relu_dense_0 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_dense_0 (Dropout)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "hidden_dense_1 (Dense)       (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "batchnorm_dense_1 (BatchNorm (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "relu_dense_1 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_dense_1 (Dropout)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "flower_prob (Dense)          (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 9,635,141\n",
      "Trainable params: 9,634,981\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 14:41:46.492279: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 81s 765ms/step - loss: 1.8874 - accuracy: 0.2842 - val_loss: 1.6435 - val_accuracy: 0.3514\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 76s 733ms/step - loss: 1.7336 - accuracy: 0.3439 - val_loss: 1.5459 - val_accuracy: 0.3784\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 78s 747ms/step - loss: 1.6439 - accuracy: 0.3715 - val_loss: 1.5551 - val_accuracy: 0.4216\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 78s 750ms/step - loss: 1.5966 - accuracy: 0.4015 - val_loss: 1.4947 - val_accuracy: 0.3838\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 77s 741ms/step - loss: 1.5834 - accuracy: 0.4073 - val_loss: 1.5271 - val_accuracy: 0.4054\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 79s 760ms/step - loss: 1.5283 - accuracy: 0.4148 - val_loss: 1.5589 - val_accuracy: 0.4243\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 79s 760ms/step - loss: 1.4973 - accuracy: 0.4339 - val_loss: 1.4787 - val_accuracy: 0.4595\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 77s 742ms/step - loss: 1.4991 - accuracy: 0.4345 - val_loss: 1.4684 - val_accuracy: 0.4514\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 78s 749ms/step - loss: 1.4693 - accuracy: 0.4406 - val_loss: 1.5223 - val_accuracy: 0.4405\n",
      "Epoch 10/10\n",
      " 95/104 [==========================>...] - ETA: 6s - loss: 1.4423 - accuracy: 0.4605"
     ]
    }
   ],
   "source": [
    "model = train_and_evaluate(dropout_prob=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! You've completed the lab!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "5UOm2etrwYCs",
    "BtsR1Fzbh4ff",
    "GPCx8a-IZpUd",
    "X9U0ob6HLUAX"
   ],
   "name": "02b_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
